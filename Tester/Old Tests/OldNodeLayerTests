using System;
using System.Collections.Generic;
using Microsoft.VisualStudio.TestTools.UnitTesting;
using NumRecog;

namespace TesterOld
{
    [TestClass]
    public class OldNodeLayerTests
    {
        [TestMethod]
        public void Test_CnstNoNeurons()
        {
            int numNodes = MLCore.rand.Next(1, 10);
            OldNodeLayer nl = new OldNodeLayer(numNodes);
            Assert.AreEqual(numNodes, nl.getNodes().Count);
        }

        [TestMethod]
        public void Test_CnstWithNeurons()
        {
            int numNodes = MLCore.rand.Next(1, 10);
            int numNeurons = MLCore.rand.Next(1, 10);
            OldNodeLayer nl = new OldNodeLayer(numNodes, numNeurons);

            Assert.AreEqual(numNodes, nl.getNodes().Count);

            for (int i = 0; i < numNodes; i++) Assert.AreEqual(numNeurons, nl.getNodes()[i].getNuerons().Count);
        }

        [TestMethod]
        public void Test_SetNodeValue()
        {
            int numNodes = MLCore.rand.Next(1, 10);
            OldNodeLayer nl = new OldNodeLayer(numNodes);

            double value = MLCore.rand.Next(10);
            int randNode = MLCore.rand.Next(numNodes - 1);
            nl.setNodeValue(value, randNode);

            Assert.AreEqual(value, nl.getNodes()[randNode].getValue());
        }

        [TestMethod]
        public void Test_GetNodeValues()
        {
            int numNodes = MLCore.rand.Next(1, 10);
            OldNodeLayer nl = new OldNodeLayer(numNodes);

            List<double> values = new List<double>();
            for (int i = 0; i < numNodes; i++)
            {
                double value = MLCore.rand.Next(10);
                values.Add(value);
                nl.setNodeValue(value, i);
            }

            List<double> nodeValues = nl.getNodeValues();
            for (int i = 0; i < numNodes; i++) Assert.AreEqual(values[i], nodeValues[i]);
        }

        [TestMethod]
        public void Test_GetWeight()
        {
            int numNodes = MLCore.rand.Next(1, 10);
            int numNeurons = MLCore.rand.Next(1, 10);
            OldNodeLayer nl = new OldNodeLayer(numNodes, numNeurons);

            int randNode = MLCore.rand.Next(numNodes - 1);
            int randNeuron = MLCore.rand.Next(numNeurons - 1);

            Assert.AreEqual
            (
                nl.getNodes()[randNode].getNuerons()[randNeuron].getWeight(),
                nl.getWeight(randNode, randNeuron)
            );
        }

        [TestMethod]
        public void Test_GetWeights()
        {
            int numNodes = MLCore.rand.Next(1, 10);
            int numNeurons = MLCore.rand.Next(1, 10);
            OldNodeLayer nl = new OldNodeLayer(numNodes, numNeurons);
            List<double> weights = nl.getWeights();
            
            for (int i = 0; i < numNodes; i++)
            {
                for (int j = 0; j < numNeurons; j++)
                {
                    int index = (i * numNeurons) + j;
                    Assert.AreEqual(nl.getWeight(i, j), weights[index]);
                }
            }
        }

        [TestMethod]
        public void Test_GetBias()
        {
            int numNodes = MLCore.rand.Next(1, 10);
            OldNodeLayer nl = new OldNodeLayer(numNodes);

            for (int i = 0; i < numNodes; i++) 
            {
                Assert.AreEqual
                (
                    nl.getNodes()[i].getBias(),
                    nl.getBias(i)
                );
            }
        }

        [TestMethod]
        public void Test_GetBiases()
        {
            int numNodes = MLCore.rand.Next(1, 10);
            OldNodeLayer nl = new OldNodeLayer(numNodes);
            List<double> biases = nl.getBiases();

            for (int i = 0; i < numNodes; i++) Assert.AreEqual(nl.getNodes()[i].getBias(), biases[i]);
        }

        [TestMethod]
        public void Test_UpdateNeurons()
        {
            int numNodes = MLCore.rand.Next(1, 10);
            int numNeurons = MLCore.rand.Next(1, 10);
            OldNodeLayer nl = new OldNodeLayer(numNodes, numNeurons);

            List<double> updates = new List<double>();
            for (int i = 0; i < numNodes * numNeurons; i++) updates.Add(MLCore.rand.NextDouble());

            List<double> weights = nl.getWeights();

            nl.updateNeurons(updates);

            for (int i = 0; i < numNodes; i++)
            {
                for (int j = 0; j < numNeurons; j++)
                {
                    int poz = i * numNeurons + j;

                    Assert.AreEqual(weights[poz] + updates[poz], nl.getWeight(i, j));
                }
            }
        }

        [TestMethod]
        public void Test_UpdateBiasesUpdatesNull()
        {
            OldNodeLayer nl = new OldNodeLayer(99);
            List<double> updates = null;

            Assert.ThrowsException<ArgumentNullException>(() => nl.updateBiases(updates));
        }

        [TestMethod]
        public void Test_UpdateBiasesUpdatesEmpty()
        {
            OldNodeLayer nl = new OldNodeLayer(99);
            List<double> updates = new List<double>();

            Assert.ThrowsException<MLCore.ArgumentWrongSizeException>(() => nl.updateBiases(updates));
        }

        [TestMethod]
        public void Test_UpdateBiasesUpdatesTooSamll()
        {
            OldNodeLayer nl = new OldNodeLayer(99);
            List<double> updates = new List<double>();

            for (int i = 0; i < 88; i++) updates.Add(MLCore.rand.NextDouble());

            Assert.ThrowsException<MLCore.ArgumentWrongSizeException>(() => nl.updateBiases(updates));
        }

        [TestMethod]
        public void Test_UpdateBiasesUpdatesTooLarge()
        {
            OldNodeLayer nl = new OldNodeLayer(99);
            List<double> updates = new List<double>();

            for (int i = 0; i < 100; i++) updates.Add(MLCore.rand.NextDouble());

            Assert.ThrowsException<MLCore.ArgumentWrongSizeException>(() => nl.updateBiases(updates));
        }
        
        [TestMethod]
        public void Test_UpdateBiasesUpdatesBiases()
        {
            int numNodes = MLCore.rand.Next(1, 10);
            OldNodeLayer nl = new OldNodeLayer(numNodes);
            List<double> biases = nl.getBiases();

            List<double> updates = new List<double>();
            for (int i = 0; i < numNodes; i++) updates.Add(MLCore.rand.NextDouble());
            nl.updateBiases(updates);

            for (int i = 0; i < numNodes; i++) Assert.AreEqual(biases[i] + updates[i], nl.getBias(i));
        }

        [TestMethod]
        public void Test_LoadWithNull()
        {
            int numNodes = MLCore.rand.Next(1, 10);
            OldNodeLayer nl = new OldNodeLayer(numNodes);
            List<int> image = null;

            Assert.ThrowsException<ArgumentNullException>(() => nl.load(image));
        }

        [DataTestMethod]
        [DataRow(0)]
        [DataRow(1)]
        [DataRow(10)]
        public void Test_LoadImageWithWrongNum(int imageLen)
        {
            int numNodes = MLCore.rand.Next(2, 9);
            OldNodeLayer nl = new OldNodeLayer(numNodes);
            List<int> image = new List<int>();
            for (int i = 0; i < imageLen; i++) image.Add(MLCore.rand.Next());

            Assert.ThrowsException<MLCore.ArgumentWrongSizeException>(() => nl.load(image));
        }

        [TestMethod]
        public void Test_LoadFunction()
        {
            int numNodes = MLCore.rand.Next(1, 10);
            OldNodeLayer nl = new OldNodeLayer(numNodes);
            List<int> image = new List<int>();
            for (int i = 0; i < numNodes; i++) image.Add(MLCore.rand.Next(256));

            nl.load(image);

            List<double> compressedImage = MLCore.compress(image, 256.0);
            for (int i = 0; i < numNodes; i++)
            {
                Assert.AreEqual
                (
                    compressedImage[i],
                    nl.getNodeValues()[i]
                );
            }
        }

        [TestMethod]
        public void Test_PropogateForward()
        {
            int numNodes = MLCore.rand.Next(1, 10);
            int numNeurons = MLCore.rand.Next(1, 10);
            OldNodeLayer nl1 = new OldNodeLayer(numNodes, numNeurons);
            OldNodeLayer nl2 = new OldNodeLayer(numNeurons);

            List<int> picture = new List<int>();
            for (int i = 0; i < numNodes; i++) picture.Add(MLCore.rand.Next(256));
            
            nl1.load(picture);
            nl1.propogateForward(nl2);

            List<double> nl1Values = nl1.getNodeValues();
            for (int i = 0; i < numNeurons; i++)
            {
                double expectedValue = MLCore.normalise(nl2.getBias(i) + MLCore.scalerProduct(nl1Values, nl1.getNeurons(i)));
                Assert.AreEqual(expectedValue, nl2.getNodeValue(i), 0.99);
            }
        }

        [TestMethod]
        public void Test_SumSquaredDiff()
        {
            List<double> a = new List<double>();
            for (int i = 0; i < 10; i++) a.Add(MLCore.rand.NextDouble());
            
            List<double> b = new List<double>();
            for (int i = 0; i < 10; i++) b.Add(MLCore.rand.NextDouble());

            double c = 0;
            for (int i = 0; i < a.Count; i++) c += Math.Pow((a[i] - b[i]), 2);

            double d = OldNodeLayer.sumSquareDiff(a, b);
            Assert.AreEqual(c, d);
        }

        [TestMethod]
        public void Test_HighestsIndex()
        {
            List<double> a = new List<double>();
            for (int i = 0; i < 10; i++) a.Add(MLCore.rand.NextDouble());

            int highestIndex = 0;
            double highest = 0.0;
            for (int i = 0; i < a.Count; i++)
            {
                if (a[i] > highest) highestIndex = i;
            }

            Assert.AreEqual(highestIndex, OldNodeLayer.highestsIndex(a));
        }
    }
}